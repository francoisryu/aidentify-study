{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import datas.mnist_data as mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터(MNIST)\n",
    "(train_labels, train_images) = mnist.get_data('./datas/', 'train')\n",
    "\n",
    "# X(이미지)와 Y(숫자값)의 입력값\n",
    "X = tf.placeholder(tf.float32, [None, 28*28]) # 무한대 x 784(28*28) 행렬\n",
    "Y = tf.placeholder(tf.int32, [None]) # 무한대 x 1 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLP Model\n",
    "def model(input_X):\n",
    "    # 모델의 wright와 bias의 배열값을 0으로 초기화\n",
    "    W = tf.Variable(tf.zeros([28*28, 10]), name=\"weight\")\n",
    "    b = tf.Variable(tf.zeros([10]), name=\"bias\")\n",
    "\n",
    "    # SoftMax 모델을 생성\n",
    "    pred = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "    return pred\n",
    "\n",
    "pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Function 설계 (Cross Entropy)\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=pred)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Gradient descent Optimizer(학습)\n",
    "# 미분을 통해서 해당 점의 기울기가 가장 작은 곳이 최적화의 포인트(learning_rate만큼의 단위로 실행)\n",
    "# 지속적으로 기울기(미분)를 측정하여 W와 b를 수정\n",
    "# W' = W - (cost함수의 미분값 * learning_rate:0.01)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.7503867\n",
      "2 1.8980119\n",
      "3 1.8349085\n",
      "4 1.7636973\n",
      "5 1.8073806\n",
      "6 1.7882292\n",
      "7 1.7511606\n",
      "8 1.7764409\n",
      "9 1.785661\n",
      "10 1.7271996\n",
      "11 1.7638203\n",
      "12 1.7814466\n",
      "13 1.7302817\n",
      "14 1.7460651\n",
      "15 1.7807554\n",
      "16 1.8088648\n",
      "17 1.8263544\n",
      "18 1.782762\n",
      "19 1.782511\n",
      "20 1.787431\n",
      "21 1.74444\n",
      "22 1.7238278\n",
      "23 1.7783576\n",
      "24 1.7565843\n",
      "25 1.790479\n",
      "26 1.7403175\n",
      "27 1.7628499\n",
      "28 1.7523836\n",
      "29 1.7142974\n",
      "30 1.7410132\n",
      "31 1.707286\n",
      "32 1.7568492\n",
      "33 1.7606492\n",
      "34 1.7776406\n",
      "35 1.7557244\n",
      "36 1.8171197\n",
      "37 1.7940614\n",
      "38 1.7745432\n",
      "39 1.7396492\n",
      "40 1.7347901\n",
      "41 1.7365414\n",
      "42 1.7443479\n",
      "43 1.7580056\n",
      "44 1.7389009\n",
      "45 1.7093164\n",
      "46 1.7299604\n",
      "47 1.7348064\n",
      "48 1.7401692\n",
      "49 1.8025005\n",
      "50 1.7802032\n",
      "51 1.750562\n",
      "52 1.7093977\n",
      "53 1.7339233\n",
      "54 1.7189455\n",
      "55 1.7210793\n",
      "56 1.7003725\n",
      "57 1.712434\n",
      "58 1.7086203\n",
      "59 1.688616\n",
      "학습완료! (cost : 1.688616)\n",
      "테스트 완료! (cost : 1.7256722)\n",
      "테스트와 학습의 cost차이 :  0.037056208\n",
      "예측값: [3] / 실제값5 => [False]\n",
      "예측값: [0] / 실제값0 => [ True]\n",
      "예측값: [4] / 실제값4 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [9] / 실제값9 => [ True]\n",
      "예측값: [9] / 실제값2 => [False]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [3] / 실제값3 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [4] / 실제값4 => [ True]\n",
      "예측값: [3] / 실제값3 => [ True]\n",
      "예측값: [8] / 실제값5 => [False]\n",
      "예측값: [3] / 실제값3 => [ True]\n",
      "예측값: [6] / 실제값6 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [7] / 실제값7 => [ True]\n",
      "예측값: [7] / 실제값2 => [False]\n",
      "예측값: [8] / 실제값8 => [ True]\n",
      "예측값: [6] / 실제값6 => [ True]\n",
      "예측값: [9] / 실제값9 => [ True]\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    index_in_epoch = 0\n",
    "    # 학습횟수(epoch:60) -> 총 60000개\n",
    "    for epoch in range(1, 60):\n",
    "        start = index_in_epoch\n",
    "        index_in_epoch += 1000 # 배치 1000개\n",
    "        end = index_in_epoch\n",
    "\n",
    "        X_images = np.reshape(train_images[start:end], [-1, 28*28])\n",
    "        Y_labels = train_labels[start:end]\n",
    "\n",
    "        sess.run(optimizer, feed_dict={X: X_images , Y: Y_labels})\n",
    "\n",
    "        # 로그\n",
    "        training_cost = sess.run(cost, feed_dict={X: X_images , Y: Y_labels})\n",
    "        print(epoch, training_cost)\n",
    "\n",
    "    print(\"학습완료! (cost : \" + str(training_cost) + \")\")\n",
    "\n",
    "    # 테스트 데이터로 테스트(총 10000개)\n",
    "    # iteration없고 optimizer없이, 테스트 데이터만 가지고 체크\n",
    "    # => cost 안에 이미 W와 b가 결정되었기 때문\n",
    "    (test_labels, test_images) = mnist.get_data('./datas/', 'test')\n",
    "\n",
    "    test_X = np.reshape(test_images, [-1, 28*28])\n",
    "    test_Y = test_labels\n",
    "\n",
    "    testing_cost = sess.run(cost, feed_dict={X: test_X, Y: test_Y})\n",
    "    print(\"테스트 완료! (cost : \" + str(testing_cost) + \")\")\n",
    "\n",
    "    # 학습과 테스트 cost비교(절대값)\n",
    "    print(\"테스트와 학습의 cost차이 : \", abs(training_cost - testing_cost))\n",
    "    # 값 예측 (10개)\n",
    "    for i in range(20):\n",
    "        x_test = np.reshape(train_images[i], [-1, 28*28])\n",
    "        arr_data = sess.run(pred, feed_dict={X: x_test})\n",
    "\n",
    "        pred_val = tf.argmax(arr_data, 1)\n",
    "        real_val = train_labels[i]\n",
    "\n",
    "        print(\"예측값: \" + str(pred_val.eval()) + \" / 실제값\" + str(real_val) + \" => \" \\\n",
    "                + str(tf.equal(pred_val, real_val).eval()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
