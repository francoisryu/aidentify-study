{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import datas.mnist_data as mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터(MNIST)\n",
    "(train_labels, train_images) = mnist.get_data('./datas/', 'train')\n",
    "\n",
    "# X(이미지)와 Y(숫자값)의 입력값\n",
    "X = tf.placeholder(tf.float32, [None, 28*28]) # 무한대 x 784(28*28) 행렬\n",
    "Y = tf.placeholder(tf.int64, [None]) # 무한대 x 1 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "def model(input_X):\n",
    "    x_reshape = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "    # Conv 레이어1\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 20], stddev=0.1)) # Filter가 Weight 역활을 함\n",
    "    b_conv1 = tf.Variable(tf.zeros([20]))\n",
    "    h_conv1 = tf.nn.conv2d(x_reshape, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\n",
    "    fmap_conv1 = tf.nn.tanh(h_conv1) # -> Feature(Activation) Map 생성\n",
    "\n",
    "    # Pooling(Max) 레이어1\n",
    "    h_pool1 = tf.nn.max_pool(fmap_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # fully-connected 레이어 1\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal([20 * 14 * 14, 500], stddev=0.1))\n",
    "    b_fc1 = tf.Variable(tf.zeros([500]))\n",
    "    h_pool1_flat = tf.reshape(h_pool1, [-1, 20 * 14 * 14])\n",
    "    h_fc1 = tf.nn.tanh(tf.matmul(h_pool1_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # 출력(fully connected) 레이어 2 (10개 출력)\n",
    "    class_num = 10\n",
    "    W_fc2 = tf.Variable(tf.truncated_normal([500, class_num], stddev=0.1))\n",
    "    b_fc2 = tf.Variable(tf.zeros([class_num]))\n",
    "    pred = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "\n",
    "    return pred\n",
    "\n",
    "pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Function 설계 (Cross Entropy)\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=pred)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Gradient descent Optimizer(학습)\n",
    "# 미분을 통해서 해당 점의 기울기가 가장 작은 곳이 최적화의 포인트(learning_rate만큼의 단위로 실행)\n",
    "# 지속적으로 기울기(미분)를 측정하여 W와 b를 수정\n",
    "# W' = W - (cost함수의 미분값 * learning_rate:0.01)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.9417157\n",
      "2 2.6754737\n",
      "3 2.6936393\n",
      "4 2.5249405\n",
      "5 2.4034755\n",
      "6 2.3439\n",
      "7 2.160578\n",
      "8 2.202883\n",
      "9 2.101635\n",
      "10 1.9969352\n",
      "11 1.9112947\n",
      "12 1.8235986\n",
      "13 1.9228446\n",
      "14 1.9092485\n",
      "15 1.8480765\n",
      "16 1.8139191\n",
      "17 1.6962494\n",
      "18 1.7525998\n",
      "19 1.5851147\n",
      "20 1.5826454\n",
      "21 1.6205764\n",
      "22 1.5089498\n",
      "23 1.5935571\n",
      "24 1.5497229\n",
      "25 1.4402862\n",
      "26 1.4022206\n",
      "27 1.4207103\n",
      "28 1.349187\n",
      "29 1.3258244\n",
      "30 1.3819871\n",
      "31 1.4116994\n",
      "32 1.3509431\n",
      "33 1.4269172\n",
      "34 1.2087125\n",
      "35 1.2368149\n",
      "36 1.2357779\n",
      "37 1.1823093\n",
      "38 1.2638359\n",
      "39 1.1588191\n",
      "40 1.1632036\n",
      "41 1.067668\n",
      "42 1.2379055\n",
      "43 1.1938039\n",
      "44 1.0014062\n",
      "45 1.0938995\n",
      "46 1.1803507\n",
      "47 1.0251341\n",
      "48 1.0413463\n",
      "49 1.006535\n",
      "50 1.2119373\n",
      "51 1.0210887\n",
      "52 0.9782732\n",
      "53 1.0059431\n",
      "54 0.96804184\n",
      "55 0.9741382\n",
      "56 0.8025063\n",
      "57 0.94394094\n",
      "58 0.9812748\n",
      "59 0.78892994\n",
      "학습완료! (cost : 0.78892994)\n",
      "테스트 완료! (cost : 0.93770623)\n",
      "테스트와 학습의 cost차이 :  0.1487763\n",
      "예측값: [3] / 실제값5 => [False]\n",
      "예측값: [0] / 실제값0 => [ True]\n",
      "예측값: [4] / 실제값4 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [9] / 실제값9 => [ True]\n",
      "예측값: [2] / 실제값2 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [8] / 실제값3 => [False]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [6] / 실제값4 => [False]\n",
      "예측값: [3] / 실제값3 => [ True]\n",
      "예측값: [2] / 실제값5 => [False]\n",
      "예측값: [3] / 실제값3 => [ True]\n",
      "예측값: [6] / 실제값6 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [7] / 실제값7 => [ True]\n",
      "예측값: [2] / 실제값2 => [ True]\n",
      "예측값: [8] / 실제값8 => [ True]\n",
      "예측값: [6] / 실제값6 => [ True]\n",
      "예측값: [9] / 실제값9 => [ True]\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    index_in_epoch = 0\n",
    "    # 학습횟수(epoch:60) -> 총 60000개\n",
    "    for epoch in range(1, 60):\n",
    "        start = index_in_epoch\n",
    "        index_in_epoch += 1000 # 배치 1000개\n",
    "        end = index_in_epoch\n",
    "\n",
    "        X_images = np.reshape(train_images[start:end], [-1, 28*28])\n",
    "        Y_labels = train_labels[start:end]\n",
    "\n",
    "        sess.run(optimizer, feed_dict={X: X_images , Y: Y_labels})\n",
    "\n",
    "        # 로그\n",
    "        training_cost = sess.run(cost, feed_dict={X: X_images , Y: Y_labels})\n",
    "        print(epoch, training_cost)\n",
    "        #print(epoch, training_cost, [W.eval(), b.eval()])\n",
    "\n",
    "    print(\"학습완료! (cost : \" + str(training_cost) + \")\")\n",
    "\n",
    "    # 테스트 데이터로 테스트(총 10000개)\n",
    "    # iteration없고 optimizer없이, 테스트 데이터만 가지고 체크\n",
    "    # => cost 안에 이미 W와 b가 결정되었기 때문\n",
    "    (test_labels, test_images) = mnist.get_data('./datas/', 'test')\n",
    "\n",
    "    test_X = np.reshape(test_images, [-1, 28*28])\n",
    "    test_Y = test_labels\n",
    "    \n",
    "    testing_cost = sess.run(cost, feed_dict={X: test_X, Y: test_Y})\n",
    "    print(\"테스트 완료! (cost : \" + str(testing_cost) + \")\")\n",
    "\n",
    "    # 학습과 테스트 cost비교(절대값)\n",
    "    print(\"테스트와 학습의 cost차이 : \", abs(training_cost - testing_cost))\n",
    "\n",
    "    # 값 예측 (10개)\n",
    "    for i in range(20):\n",
    "        x_test = np.reshape(train_images[i], [-1, 28*28])\n",
    "        arr_data = sess.run(pred, feed_dict={X: x_test})\n",
    "\n",
    "        pred_val = tf.argmax(arr_data, 1)\n",
    "        real_val = train_labels[i]\n",
    "\n",
    "        print(\"예측값: \" + str(pred_val.eval()) + \" / 실제값\" + str(real_val) + \" => \" + str(tf.equal(pred_val, real_val).eval()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
