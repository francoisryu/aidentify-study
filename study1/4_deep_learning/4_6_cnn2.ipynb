{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import datas.mnist_data as mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터(MNIST)\n",
    "(train_labels, train_images) = mnist.get_data('./datas/', 'train')\n",
    "\n",
    "# X(이미지)와 Y(숫자값)의 입력값\n",
    "X = tf.placeholder(tf.float32, [None, 28*28]) # 무한대 x 784(28*28) 행렬\n",
    "Y = tf.placeholder(tf.int64, [None]) # 무한대 x 1 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "def model(input_X):\n",
    "    x_reshape = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "    # Conv 레이어1\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 20], stddev=0.1)) # Filter가 Weight 역활을 함\n",
    "    b_conv1 = tf.Variable(tf.zeros([20]))\n",
    "    h_conv1 = tf.nn.conv2d(x_reshape, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\n",
    "    fmap_conv1 = tf.nn.tanh(h_conv1) # -> Feature(Activation) Map 생성\n",
    "\n",
    "    # Pooling(Max) 레이어1\n",
    "    h_pool1 = tf.nn.max_pool(fmap_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Conv 레이어2\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 20, 50], stddev=0.1)) # Filter가 Weight 역활을 함\n",
    "    b_conv2 = tf.Variable(tf.zeros([50]))\n",
    "    h_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2\n",
    "    fmap_conv2 = tf.nn.tanh(h_conv2) # -> Feature(Activation) Map 생성\n",
    "\n",
    "    # Pooling(Max) 레이어2\n",
    "    h_pool2 = tf.nn.max_pool(fmap_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # fully-connected 레이어 1\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal([50 * 7 * 7, 500], stddev=0.1))\n",
    "    b_fc1 = tf.Variable(tf.zeros([500]))\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 50 * 7 * 7])\n",
    "    h_fc1 = tf.nn.tanh(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # 출력(fully connected) 레이어 2 (10개 출력)\n",
    "    class_num = 10\n",
    "    W_fc2 = tf.Variable(tf.truncated_normal([500, class_num], stddev=0.1))\n",
    "    b_fc2 = tf.Variable(tf.zeros([class_num]))\n",
    "    pred = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "\n",
    "    return pred\n",
    "\n",
    "pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Function 설계 (Cross Entropy)\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=pred)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Gradient descent Optimizer(학습)\n",
    "# 미분을 통해서 해당 점의 기울기가 가장 작은 곳이 최적화의 포인트(learning_rate만큼의 단위로 실행)\n",
    "# 지속적으로 기울기(미분)를 측정하여 W와 b를 수정\n",
    "# W' = W - (cost함수의 미분값 * learning_rate:0.01)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.8834023\n",
      "2 2.6790378\n",
      "3 2.4239645\n",
      "4 2.3403795\n",
      "5 2.2267876\n",
      "6 2.088479\n",
      "7 2.0201745\n",
      "8 2.0252404\n",
      "9 1.8870864\n",
      "10 1.8430514\n",
      "11 1.776801\n",
      "12 1.7145612\n",
      "13 1.7280375\n",
      "14 1.6976445\n",
      "15 1.7082736\n",
      "16 1.5753155\n",
      "17 1.5494329\n",
      "18 1.6005075\n",
      "19 1.3957056\n",
      "20 1.425155\n",
      "21 1.4269668\n",
      "22 1.3697368\n",
      "23 1.4294217\n",
      "24 1.3080713\n",
      "25 1.3055706\n",
      "26 1.226788\n",
      "27 1.2051196\n",
      "28 1.2498722\n",
      "29 1.1519587\n",
      "30 1.2208596\n",
      "31 1.1905044\n",
      "32 1.2271297\n",
      "33 1.2298484\n",
      "34 1.0491599\n",
      "35 1.0995607\n",
      "36 1.0753398\n",
      "37 0.9874339\n",
      "38 1.0684307\n",
      "39 0.9832345\n",
      "40 1.0282269\n",
      "41 1.0153321\n",
      "42 1.0206051\n",
      "43 1.0364976\n",
      "44 0.9581321\n",
      "45 1.0002047\n",
      "46 0.97041166\n",
      "47 0.93552005\n",
      "48 0.9452676\n",
      "49 0.8229323\n",
      "50 1.0153134\n",
      "51 0.8518617\n",
      "52 0.8388412\n",
      "53 0.85759705\n",
      "54 0.8223206\n",
      "55 0.8395384\n",
      "56 0.7701665\n",
      "57 0.7826421\n",
      "58 0.80220175\n",
      "59 0.6887384\n",
      "학습완료! (cost : 0.6887384)\n",
      "테스트 완료! (cost : 0.8109547)\n",
      "테스트와 학습의 cost차이 :  0.122216284\n",
      "예측값: [3] / 실제값5 => [False]\n",
      "예측값: [0] / 실제값0 => [ True]\n",
      "예측값: [4] / 실제값4 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [9] / 실제값9 => [ True]\n",
      "예측값: [2] / 실제값2 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [3] / 실제값3 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [4] / 실제값4 => [ True]\n",
      "예측값: [3] / 실제값3 => [ True]\n",
      "예측값: [5] / 실제값5 => [ True]\n",
      "예측값: [3] / 실제값3 => [ True]\n",
      "예측값: [6] / 실제값6 => [ True]\n",
      "예측값: [1] / 실제값1 => [ True]\n",
      "예측값: [7] / 실제값7 => [ True]\n",
      "예측값: [2] / 실제값2 => [ True]\n",
      "예측값: [5] / 실제값8 => [False]\n",
      "예측값: [4] / 실제값6 => [False]\n",
      "예측값: [7] / 실제값9 => [False]\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    index_in_epoch = 0\n",
    "    # 학습횟수(epoch:60) -> 총 60000개\n",
    "    for epoch in range(1, 60):\n",
    "        start = index_in_epoch\n",
    "        index_in_epoch += 1000 # 배치 1000개\n",
    "        end = index_in_epoch\n",
    "\n",
    "        X_images = np.reshape(train_images[start:end], [-1, 28*28])\n",
    "        Y_labels = train_labels[start:end]\n",
    "\n",
    "        sess.run(optimizer, feed_dict={X: X_images , Y: Y_labels})\n",
    "\n",
    "        # 로그\n",
    "        training_cost = sess.run(cost, feed_dict={X: X_images , Y: Y_labels})\n",
    "        print(epoch, training_cost)\n",
    "        #print(epoch, training_cost, [W.eval(), b.eval()])\n",
    "\n",
    "    print(\"학습완료! (cost : \" + str(training_cost) + \")\")\n",
    "\n",
    "    # 테스트 데이터로 테스트(총 10000개)\n",
    "    # iteration없고 optimizer없이, 테스트 데이터만 가지고 체크\n",
    "    # => cost 안에 이미 W와 b가 결정되었기 때문\n",
    "    (test_labels, test_images) = mnist.get_data('./datas/', 'test')\n",
    "\n",
    "    test_X = np.reshape(test_images, [-1, 28*28])\n",
    "    test_Y = test_labels\n",
    "\n",
    "    testing_cost = sess.run(cost, feed_dict={X: test_X, Y: test_Y})\n",
    "    print(\"테스트 완료! (cost : \" + str(testing_cost) + \")\")\n",
    "\n",
    "    # 학습과 테스트 cost비교(절대값)\n",
    "    print(\"테스트와 학습의 cost차이 : \", abs(training_cost - testing_cost))\n",
    "    \n",
    "    # 값 예측 (10개)\n",
    "    for i in range(20):\n",
    "        x_test = np.reshape(train_images[i], [-1, 28*28])\n",
    "        arr_data = sess.run(pred, feed_dict={X: x_test})\n",
    "\n",
    "        pred_val = tf.argmax(arr_data, 1)\n",
    "        real_val = train_labels[i]\n",
    "\n",
    "        print(\"예측값: \" + str(pred_val.eval()) + \" / 실제값\" + str(real_val) + \" => \" + str(tf.equal(pred_val, real_val).eval()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
