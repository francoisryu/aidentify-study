{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-6bcf5cf4c8b7>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "#import datas.mnist_data as mnist_local\n",
    "from data import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 생성된 MNIST 이미지를 8x8 Grid로 보여주는 plot 함수를 정의합니다.\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    gs = gridspec.GridSpec(6, 6)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(sample.reshape(28, 28))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 트레이닝 파라메터\n",
    "learning_rate = 0.0002\n",
    "num_steps = 70000\n",
    "batch_size = 128\n",
    "\n",
    "display_step = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 네트워크 파라메터\n",
    "gen_hidden_dim = 256 # generator hidden dim\n",
    "disc_hidden_dim = 256 # discriminator hidden dim\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "noise_dim = 100 # Noise data points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 생성된 이미지들을 저장할 generated_outputs 폴더를 생성합니다.\n",
    "num_img = 0\n",
    "if not os.path.exists('generated_output/'):\n",
    "    os.makedirs('generated_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 변수 초기화 (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight & bias 변수\n",
    "weights = {\n",
    "    'gen_hidden1': tf.Variable(glorot_init([noise_dim, gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(glorot_init([gen_hidden_dim, num_input])),\n",
    "    'disc_hidden1': tf.Variable(glorot_init([num_input, disc_hidden_dim])),\n",
    "    'disc_out': tf.Variable(glorot_init([disc_hidden_dim, 1])),\n",
    "}\n",
    "biases = {\n",
    "    'gen_hidden1': tf.Variable(tf.zeros([gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(tf.zeros([num_input])),\n",
    "    'disc_hidden1': tf.Variable(tf.zeros([disc_hidden_dim])),\n",
    "    'disc_out': tf.Variable(tf.zeros([1])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "def generator(x):\n",
    "    hidden_layer = tf.matmul(x, weights['gen_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['gen_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['gen_out'])\n",
    "    out_layer = tf.add(out_layer, biases['gen_out'])\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def discriminator(x):\n",
    "    hidden_layer = tf.matmul(x, weights['disc_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['disc_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['disc_out'])\n",
    "    out_layer = tf.add(out_layer, biases['disc_out'])\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Networks\n",
    "# Network Inputs\n",
    "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')\n",
    "disc_input = tf.placeholder(tf.float32, shape=[None, num_input], name='disc_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "gen_sample = generator(gen_input)\n",
    "\n",
    "# 두 개의 Discriminator Network 생성 (one from noise input, one from generated samples)\n",
    "disc_real = discriminator(disc_input)\n",
    "disc_fake = discriminator(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "gen_loss = -tf.reduce_mean(tf.log(disc_fake))\n",
    "disc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n",
    "\n",
    "# Optimizer\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 각각의 optimizer 의 훈련 변수\n",
    "# Generator Network 변수\n",
    "gen_vars = [weights['gen_hidden1'], weights['gen_out'],\n",
    "            biases['gen_hidden1'], biases['gen_out']]\n",
    "# Discriminator Network Variables\n",
    "disc_vars = [weights['disc_hidden1'], weights['disc_out'],\n",
    "            biases['disc_hidden1'], biases['disc_out']]\n",
    "\n",
    "# 최적화\n",
    "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
    "train_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Generator Loss: 0.982961, Discriminator Loss: 1.211997\n",
      "Step 2000: Generator Loss: 4.803146, Discriminator Loss: 0.047324\n",
      "Step 4000: Generator Loss: 4.271582, Discriminator Loss: 0.056077\n",
      "Step 6000: Generator Loss: 4.099272, Discriminator Loss: 0.102769\n",
      "Step 8000: Generator Loss: 3.917368, Discriminator Loss: 0.185384\n",
      "Step 10000: Generator Loss: 4.003447, Discriminator Loss: 0.178730\n",
      "Step 12000: Generator Loss: 3.551331, Discriminator Loss: 0.215322\n",
      "Step 14000: Generator Loss: 4.158388, Discriminator Loss: 0.166747\n",
      "Step 16000: Generator Loss: 4.063971, Discriminator Loss: 0.127277\n",
      "Step 18000: Generator Loss: 3.962307, Discriminator Loss: 0.161338\n",
      "Step 20000: Generator Loss: 3.395291, Discriminator Loss: 0.396028\n",
      "Step 22000: Generator Loss: 4.415396, Discriminator Loss: 0.131401\n",
      "Step 24000: Generator Loss: 3.454681, Discriminator Loss: 0.255989\n"
     ]
    }
   ],
   "source": [
    "# TF session 시작\n",
    "sess = tf.Session()\n",
    "\n",
    "# initializer 실행\n",
    "sess.run(init)\n",
    "\n",
    "# 훈련 시작\n",
    "for i in range(1, num_steps+1):\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "    \n",
    "    # Generator 에 feed 하기 위한 노이즈 생성\n",
    "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "    \n",
    "    # 500번 반복할때마다 생성된 이미지를 저장합니다.\n",
    "    if i % 500 == 0:\n",
    "        samples = sess.run(gen_sample, feed_dict={gen_input: np.random.uniform(-1., 1., [36, 100])})\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('generated_output/GAN/%s-iter%d.png' % (str(num_img).zfill(3), i), bbox_inches='tight')\n",
    "        num_img += 1\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # 훈련\n",
    "    feed_dict = {disc_input: batch_x, gen_input: z}\n",
    "    _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n",
    "                            feed_dict=feed_dict)\n",
    "    if i % display_step == 0 or i == 1:\n",
    "        print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (i, gl, dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 테스트 시작\n",
    "# 노이즈로부터 이미지를 생성\n",
    "n = 6\n",
    "canvas = np.empty((28 * n, 28 * n))\n",
    "for i in range(n):\n",
    "    # 노이즈 입력\n",
    "    z = np.random.uniform(-1., 1., size=[n, noise_dim])\n",
    "    \n",
    "    # 이미지 생성\n",
    "    g = sess.run(gen_sample, feed_dict={gen_input: z})\n",
    "    \n",
    "    g = -1 * (g - 1)\n",
    "    for j in range(n):\n",
    "        canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
